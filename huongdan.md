control + F: final code
PHáº¦N 0 â€“ HIá»‚U DATASET (Báº®T BUá»˜C TRÆ¯á»šC KHI CODE)

ğŸ“„ File: ObesityDataset.csv

2111 dÃ²ng, 14 features, 1 target

Target: NObesity (6 lá»›p â†’ bÃ i toÃ¡n multi-class classification)

NhÃ³m thuá»™c tÃ­nh
Loáº¡i	Cá»™t
Numeric	age, FCVC, NCP, CH20, FAF, TUE
Categorical	gender, family_history, FAVC, CAEC, SMOKE, SCC, CALC, MTRANS

ğŸ“Œ Äiá»ƒm giáº£ng viÃªn hay báº¯t lá»—i
âŒ Encode trÆ°á»›c khi split
âŒ Scale ngoÃ i pipeline
âŒ KhÃ´ng dÃ¹ng ColumnTransformer

PHáº¦N 1 â€“ MODELING (50%)
BÆ¯á»šC 1.1 â€“ Train / Test Split (Báº®T BUá»˜C ÄÃšNG THAM Sá»)
â€¢ Test size = 20%
â€¢ Stratify = y
â€¢ random_state = 42


ğŸ¯ Má»¥c Ä‘Ã­ch:

Giá»¯ phÃ¢n bá»‘ 6 lá»›p obesity giá»‘ng nhau á»Ÿ train & test

ğŸ“Œ Báº¡n cáº§n:

X = dataframe.drop("NObesity")

y = dataframe["NObesity"]

BÆ¯á»šC 1.2 â€“ XÃC Äá»ŠNH Cá»˜T NUMERIC & CATEGORICAL

KhÃ´ng Ä‘oÃ¡n, pháº£i liá»‡t kÃª rÃµ trong code

numeric_features = [...]
categorical_features = [...]


ğŸ“Œ Giáº£ng viÃªn cháº¥m ráº¥t ká»¹ pháº§n nÃ y

BÆ¯á»šC 1.3 â€“ PREPROCESSING (Ráº¤T QUAN TRá»ŒNG)
YÃªu cáº§u Ä‘á» bÃ i

One-Hot Encoding cho categorical

Scaling cho numeric

Táº¤T Cáº¢ náº±m trong Pipeline

Cáº¥u trÃºc chuáº©n (báº¯t buá»™c nhá»›):
ColumnTransformer
 â”œâ”€â”€ numeric_pipeline (StandardScaler)
 â””â”€â”€ categorical_pipeline (OneHotEncoder)


ğŸ“Œ TUYá»†T Äá»I KHÃ”NG:

pd.get_dummies() bÃªn ngoÃ i

scaler.fit_transform() trÆ°á»›c pipeline

BÆ¯á»šC 1.4 â€“ XÃ‚Y Dá»°NG CÃC MÃ” HÃŒNH
Sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh

Ãt nháº¥t n + 1 model
(n = sá»‘ thÃ nh viÃªn nhÃ³m)

VÃ­ dá»¥ nhÃ³m 3 ngÆ°á»i â†’ â‰¥ 4 models

Má»—i model pháº£i lÃ :
Pipeline(
  preprocessing
  â†’ classifier
)

Model Ä‘Æ°á»£c khuyáº¿n nghá»‹

Báº¡n cÃ³ thá»ƒ chá»n:

Logistic Regression

Decision Tree

Random Forest

KNN

Naive Bayes

ğŸ“Œ Má»—i model:

fit(X_train, y_train)

predict(X_test)

predict_proba(X_test) â† báº¯t buá»™c cho ROC-AUC

PHáº¦N 2 â€“ EVALUATION (25%)
BÆ¯á»šC 2.1 â€“ METRICS Báº®T BUá»˜C
1ï¸âƒ£ Performance Overview

Accuracy

Confusion Matrix (váº½ heatmap)

ğŸ“Œ Giáº£i thÃ­ch:

Class nÃ o bá»‹ nháº§m nhiá»u?

Obesity I â†” Obesity II cÃ³ bá»‹ nháº§m khÃ´ng?

2ï¸âƒ£ Classification Report (MACRO)

Báº N PHáº¢I Láº¤Y:

Macro Precision

Macro Recall

Macro F1-score

ğŸ“Œ Táº¡i sao dÃ¹ng macro?
â†’ Dataset multi-class + cÃ³ thá»ƒ imbalance

3ï¸âƒ£ ROC â€“ AUC (KHÃ“ NHáº¤T)

ğŸ“Œ YÃªu cáº§u:

Macro-averaged ROC-AUC

DÃ¹ng predict_proba

Binarize label (OneVsRest)

ğŸ¯ Ã nghÄ©a:

Kháº£ nÄƒng phÃ¢n biá»‡t tá»•ng thá»ƒ cá»§a model

BÆ¯á»šC 2.2 â€“ SO SÃNH & PHÃ‚N TÃCH

Báº¡n cáº§n viáº¿t phÃ¢n tÃ­ch báº±ng lá»i, KHÃ”NG chá»‰ báº£ng sá»‘:

Gá»£i Ã½ cáº¥u trÃºc:

Model nÃ o accuracy cao nháº¥t

Model nÃ o á»•n Ä‘á»‹nh nháº¥t (macro-F1)

PhÃ¢n tÃ­ch confusion matrix

CÃ³ imbalance khÃ´ng?

VÃ¬ sao model A > model B?

ğŸ“Œ ÄÃ¢y lÃ  pháº§n Äƒn Ä‘iá»ƒm 25%

PHáº¦N 3 â€“ DEPLOYMENT (25%)
BÆ¯á»šC 3.1 â€“ CHá»ŒN MODEL Tá»T NHáº¤T

ğŸ‘‰ Dá»±a trÃªn:

Accuracy

Macro-F1

ROC-AUC

Äá»™ á»•n Ä‘á»‹nh

ğŸ“Œ KhÃ´ng pháº£i cá»© RandomForest lÃ  tá»‘t nháº¥t â†’ pháº£i cÃ³ lÃ½ do

BÆ¯á»šC 3.2 â€“ LÆ¯U & LOAD PIPELINE

LÆ°u TOÃ€N Bá»˜ pipeline

KhÃ´ng chá»‰ model

DÃ¹ng joblib hoáº·c pickle

ğŸ“Œ VÃ¬:

Input web â†’ preprocessing â†’ model â†’ output

BÆ¯á»šC 3.3 â€“ Táº O WEB Báº°NG GRADIO

Web gá»“m:

Input cho 14 features

Button Predict

Output: NObesity

ğŸ“Œ Giao diá»‡n giá»‘ng hÃ¬nh demo trang 5 cá»§a Ä‘á» 

DIY 2

BÆ¯á»šC 3.4 â€“ DEPLOY HUGGING FACE

Repo HuggingFace Spaces

SDK: Gradio

File chÃ­nh: app.py

Upload model Ä‘Ã£ save

CHIáº¾N LÆ¯á»¢C LÃ€M BÃ€I TRONG 3 GIá»œ
Thá»i gian	Viá»‡c
30â€™	Äá»c Ä‘á» + phÃ¢n tÃ­ch dataset
60â€™	Modeling (pipelines + models)
40â€™	Evaluation
30â€™	So sÃ¡nh & chá»n model
20â€™	Gradio demo
20â€™	Kiá»ƒm tra & hoÃ n thiá»‡n







1ï¸âƒ£ PSEUDO-CODE Tá»ªNG PHáº¦N (Äá»‚ Báº N Tá»° CODE)
1. Äá»c dá»¯ liá»‡u & tÃ¡ch X, y
LOAD ObesityDataset.csv

X = dataframe bá» cá»™t NObesity
y = dataframe["NObesity"]


ğŸ“Œ LÃ½ do:

TÃ¡ch rÃµ feature vÃ  target

TrÃ¡nh leakage khi preprocessing

2. Trainâ€“Test Split (Báº®T BUá»˜C)
SPLIT X, y thÃ nh:
- 80% train
- 20% test
- stratify = y
- random_state = 42


ğŸ“Œ Giáº£i thÃ­ch Ä‘á»ƒ ghi vÃ o bÃ¡o cÃ¡o

Viá»‡c sá»­ dá»¥ng stratified split giÃºp Ä‘áº£m báº£o phÃ¢n bá»‘ cÃ¡c lá»›p bÃ©o phÃ¬ Ä‘Æ°á»£c giá»¯ nguyÃªn giá»¯a táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra, Ä‘áº·c biá»‡t quan trá»ng trong bÃ i toÃ¡n phÃ¢n loáº¡i nhiá»u lá»›p.

3. PhÃ¢n loáº¡i cá»™t (Ráº¤T QUAN TRá»ŒNG)
numeric_features = [
  age, FCVC, NCP, CH20, FAF, TUE
]

categorical_features = [
  gender, family_history_with_overweight,
  FAVC, CAEC, SMOKE, SCC,
  CALC, MTRANS
]


ğŸ“Œ Giáº£ng viÃªn hay há»i miá»‡ng:

â€œTáº¡i sao FCVC lÃ  numeric?â€ â†’ VÃ¬ nÃ³ lÃ  táº§n suáº¥t dáº¡ng sá»‘.

4. Preprocessing Pipeline (KHÃ”NG ÄÆ¯á»¢C LÃ€M NGOÃ€I)
Numeric pipeline
numeric_pipeline:
  StandardScaler

Categorical pipeline
categorical_pipeline:
  OneHotEncoder (handle_unknown = ignore)

ColumnTransformer
preprocessor:
  apply numeric_pipeline cho numeric_features
  apply categorical_pipeline cho categorical_features


ğŸ“Œ CÃ¢u tháº§n chÃº

KhÃ´ng preprocessing ngoÃ i pipeline â†’ trÃ¡nh data leakage

5. XÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh (n + 1 models)

VÃ­ dá»¥ má»—i model Ä‘á»u cÃ³ dáº¡ng:

pipeline_model_X:
  preprocessor
  â†’ classifier_X


VÃ­ dá»¥ classifier:

Logistic Regression

Decision Tree

Random Forest

KNN

Naive Bayes

ğŸ“Œ Báº¯t buá»™c:

.fit(X_train, y_train)

.predict(X_test)

.predict_proba(X_test)

6. LÆ°u output Ä‘á»ƒ Evaluation
For má»—i model:
  y_pred = predict(X_test)
  y_proba = predict_proba(X_test)


ğŸ“Œ LÆ°u láº¡i Ä‘á»ƒ dÃ¹ng cho:

Confusion Matrix

Classification Report

ROCâ€“AUC

2ï¸âƒ£ TEMPLATE BÃO CÃO EVALUATION & ANALYSIS (COPY DÃ™NG ÄÆ¯á»¢C)
2.1 Evaluation Metrics
Accuracy

Accuracy measures the overall proportion of correctly classified samples across all obesity classes.

Confusion Matrix

The confusion matrix provides insights into how the model misclassifies between obesity levels.
We observe that misclassifications mainly occur between neighboring classes such as Overweight and Obesity I, which is reasonable due to similar BMI ranges.

Classification Report (Macro)

Macro-averaged precision, recall, and F1-score are used to treat all classes equally, regardless of their sample size.

ROCâ€“AUC (Macro)

Macro ROCâ€“AUC evaluates the overall discriminative ability of the model across all classes using a one-vs-rest strategy.

2.2 Model Comparison
Model	Accuracy	Macro F1	Macro ROCâ€“AUC
Logistic Regression			
Decision Tree			
Random Forest			
KNN			
2.3 Analysis & Discussion (PHáº¦N Ä‚N ÄIá»‚M)

Among all evaluated models, Random Forest achieved the best overall performance in terms of accuracy and macro F1-score.
The confusion matrix shows fewer misclassifications between distant obesity classes compared to other models.

Logistic Regression performed reasonably well but struggled to separate higher obesity levels, likely due to its linear decision boundary.

KNN showed sensitivity to feature scaling and may be affected by the high dimensionality after one-hot encoding.

ğŸ“Œ Káº¿t luáº­n máº«u

Based on the evaluation results and dataset characteristics, Random Forest is selected as the best-performing model for deployment.

3ï¸âƒ£ GIáº¢I THÃCH ROCâ€“AUC MULTI-CLASS (Cá»°C Dá»„ HIá»‚U)
3.1 ROCâ€“AUC lÃ  gÃ¬ (1 cÃ¢u)

ROCâ€“AUC Ä‘o kháº£ nÄƒng mÃ´ hÃ¬nh phÃ¢n biá»‡t Ä‘Ãºng giá»¯a cÃ¡c lá»›p, khÃ´ng phá»¥ thuá»™c vÃ o threshold.

3.2 Váº¥n Ä‘á»: nhiá»u hÆ¡n 2 lá»›p thÃ¬ sao?

Dataset cÃ³ 6 lá»›p â†’ khÃ´ng thá»ƒ váº½ 1 Ä‘Æ°á»ng ROC duy nháº¥t.

â¡ï¸ Giáº£i phÃ¡p: One-vs-Rest (OvR)

3.3 One-vs-Rest lÃ  gÃ¬?

VÃ­ dá»¥ lá»›p Obesity I:

Xem Obesity I lÃ  Positive

5 lá»›p cÃ²n láº¡i lÃ  Negative
â†’ tÃ­nh ROCâ€“AUC

LÃ m nhÆ° váº­y 6 láº§n â†’ láº¥y trung bÃ¬nh (macro)

3.4 Macro ROCâ€“AUC cÃ³ Ã½ nghÄ©a gÃ¬?

Macro ROCâ€“AUC reflects the modelâ€™s average discriminative performance across all obesity levels, treating each class equally.

ğŸ“Œ Táº¡i sao khÃ´ng dÃ¹ng micro?
â†’ VÃ¬ class imbalance â†’ macro cÃ´ng báº±ng hÆ¡n

4ï¸âƒ£ HÆ¯á»šNG DáºªN DEPLOY HUGGINGFACE (Tá»ªNG BÆ¯á»šC)
BÆ¯á»šC 1 â€“ Save pipeline
SAVE best_pipeline as "model.pkl"


ğŸ“Œ KhÃ´ng save riÃªng model
â†’ pháº£i save cáº£ preprocessing + model

BÆ¯á»šC 2 â€“ Táº¡o file app.py

Pseudo-structure:

LOAD model.pkl

DEFINE function predict(
  gender, age, family_history, ...
):
  CREATE dataframe tá»« input
  prediction = pipeline.predict(data)
  RETURN prediction

BÆ¯á»šC 3 â€“ Gradio Interface
gr.Interface(
  fn = predict,
  inputs = [
    Dropdown, Number, Slider, ...
  ],
  outputs = Text
)


ğŸ“Œ Input pháº£i Ä‘á»§ 14 features

BÆ¯á»šC 4 â€“ HuggingFace Spaces

Táº¡o account HF

New Space

SDK: Gradio

Upload:

app.py

model.pkl

requirements.txt

BÆ¯á»šC 5 â€“ Test online

Nháº­p dá»¯ liá»‡u

Nháº¥n Predict

Tráº£ vá»: NObesity




// Final Code
PHáº¦N 0 â€“ IMPORT THÆ¯ VIá»†N
import pandas as pd
import numpy as np

# Train-test split
from sklearn.model_selection import train_test_split

# Preprocessing
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

# Evaluation
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    classification_report,
    roc_auc_score
)

# ROC-AUC multi-class
from sklearn.preprocessing import label_binarize

# Visualization
import seaborn as sns
import matplotlib.pyplot as plt

# Save model
import joblib

PHáº¦N 1 â€“ LOAD DATASET
df = pd.read_csv("ObesityDataset.csv")

print(df.shape)
print(df.head())

PHáº¦N 2 â€“ TÃCH X, y
X = df.drop(columns=["NObesity"])
y = df["NObesity"]

PHáº¦N 3 â€“ TRAIN / TEST SPLIT (Báº®T BUá»˜C ÄÃšNG)
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

PHáº¦N 4 â€“ XÃC Äá»ŠNH Cá»˜T NUMERIC & CATEGORICAL
numeric_features = [
    "Age", "FCVC", "NCP", "CH2O", "FAF", "TUE"
]

categorical_features = [
    "Gender",
    "family_history_with_overweight",
    "FAVC",
    "CAEC",
    "SMOKE",
    "SCC",
    "CALC",
    "MTRANS"
]


ğŸ“Œ TÃªn cá»™t pháº£i Ä‘Ãºng 100% vá»›i CSV
(Náº¿u khÃ¡c â†’ print(df.columns) Ä‘á»ƒ kiá»ƒm tra)

PHáº¦N 5 â€“ PREPROCESSING PIPELINE (Ráº¤T QUAN TRá»ŒNG)
numeric_transformer = Pipeline(steps=[
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

PHáº¦N 6 â€“ XÃ‚Y Dá»°NG CÃC MÃ” HÃŒNH (n + 1)
6.1 Logistic Regression
logistic_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", LogisticRegression(max_iter=1000))
])

6.2 Decision Tree
dt_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", DecisionTreeClassifier(random_state=42))
])

6.3 Random Forest
rf_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", RandomForestClassifier(
        n_estimators=100,
        random_state=42
    ))
])

6.4 KNN
knn_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", KNeighborsClassifier(n_neighbors=5))
])

6.5 Naive Bayes (lÆ°u Ã½ riÃªng)

âš ï¸ GaussianNB khÃ´ng lÃ m viá»‡c trá»±c tiáº¿p vá»›i sparse matrix, nÃªn cáº§n máº¹o nhá»:

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import FunctionTransformer

dense_transformer = FunctionTransformer(
    lambda x: x.toarray(), accept_sparse=True
)

nb_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("to_dense", dense_transformer),
    ("classifier", GaussianNB())
])

PHáº¦N 7 â€“ TRAIN MODELS
models = {
    "Logistic Regression": logistic_pipeline,
    "Decision Tree": dt_pipeline,
    "Random Forest": rf_pipeline,
    "KNN": knn_pipeline,
    "Naive Bayes": nb_pipeline
}

for name, model in models.items():
    model.fit(X_train, y_train)

PHáº¦N 8 â€“ EVALUATION
8.1 Accuracy + Confusion Matrix
for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    print(f"\n{name}")
    print("Accuracy:", acc)

    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

8.2 Classification Report (MACRO)
for name, model in models.items():
    y_pred = model.predict(X_test)

    print(f"\n{name}")
    print(classification_report(y_test, y_pred))


ğŸ“Œ Láº¥y macro avg Ä‘á»ƒ ghi bÃ¡o cÃ¡o

8.3 ROCâ€“AUC MULTI-CLASS (KHÃ“ NHáº¤T)
classes = y.unique()
y_test_bin = label_binarize(y_test, classes=classes)

for name, model in models.items():
    y_proba = model.predict_proba(X_test)

    roc_auc = roc_auc_score(
        y_test_bin,
        y_proba,
        average="macro",
        multi_class="ovr"
    )

    print(f"{name} - Macro ROC-AUC: {roc_auc:.4f}")

PHáº¦N 9 â€“ CHá»ŒN & SAVE MODEL Tá»T NHáº¤T

Giáº£ sá»­ Random Forest tá»‘t nháº¥t:

joblib.dump(rf_pipeline, "best_model.pkl")

PHáº¦N 10 â€“ GRADIO APP (app.py)
import gradio as gr
import joblib
import pandas as pd

model = joblib.load("best_model.pkl")

def predict_obesity(
    Gender, Age, family_history, FAVC, FCVC, NCP,
    CAEC, SMOKE, CH2O, SCC, FAF, TUE, CALC, MTRANS
):
    data = pd.DataFrame([{
        "Gender": Gender,
        "Age": Age,
        "family_history_with_overweight": family_history,
        "FAVC": FAVC,
        "FCVC": FCVC,
        "NCP": NCP,
        "CAEC": CAEC,
        "SMOKE": SMOKE,
        "CH2O": CH2O,
        "SCC": SCC,
        "FAF": FAF,
        "TUE": TUE,
        "CALC": CALC,
        "MTRANS": MTRANS
    }])

    prediction = model.predict(data)[0]
    return prediction

Interface
interface = gr.Interface(
    fn=predict_obesity,
    inputs=[
        gr.Dropdown(["Male", "Female"]),
        gr.Number(),
        gr.Dropdown(["yes", "no"]),
        gr.Dropdown(["yes", "no"]),
        gr.Slider(1, 3),
        gr.Slider(1, 4),
        gr.Dropdown(["no", "Sometimes", "Frequently", "Always"]),
        gr.Dropdown(["yes", "no"]),
        gr.Slider(1, 3),
        gr.Dropdown(["yes", "no"]),
        gr.Slider(0, 3),
        gr.Slider(0, 2),
        gr.Dropdown(["no", "Sometimes", "Frequently", "Always"]),
        gr.Dropdown(["Automobile", "Bike", "Motorbike", "Public_Transportation", "Walking"])
    ],
    outputs="text",
    title="Obesity Level Prediction"
)

interface.launch()